---
title: "Probabilistic multi-group comparison of alpha diversity"
author: "Rasmus Hindstr√∂m"
date: last-modified
format:
    gfm:
        toc: true
---

# 0. Summary

This report demonstrates the use and interpretation of a probabilisitc alternative
to multi-group comparisons of alpha diversity. The basis is a multi-level model
with a group-level effect, which is estimated using Bayesian estimation with the `brms` package.


# 1. Data preparation

Preparing data from the `mia` package.

```{r}
#| label: load-libraries
#| code-summary: Load required libraries
#| echo: true
#| output: false
library(mia)
library(dplyr)
library(brms)
library(bayesplot)
library(dunn.test)
library(ggplot2)
library(patchwork)
```

```{r}
#| label: prepare-data
#| code-summary: prepare example data
data("peerj13075", package = "mia")
tse <- peerj13075
tse <- addAlpha(
    tse,
    assay.type = "counts",
    index = "shannon"
)
df <- as.data.frame(colData(tse))
```

# 2. Model fitting

The model is fitted using the `brm` function from the `brms` package.
Reponse variable is the Shannon index, and the grouping variable is the 3 classes
of `age`; `Adult`, `Middle_age`, and `Elderly`.

The model is parametrized with the group `Adult` as the baseline to which others
are compared to.

Model definition is as follows:

$$
y_{ik} \sim \text{t}(\nu, \mu_{ik}, \sigma_k)
$$

$$
\mu_{ik} = \beta_0 + \beta_k
$$

$$
\sigma_k = \gamma_0 + \gamma_k
$$

*Default priors used by `brm()`*

$$
\nu \sim \gamma(2, 0.1)
$$
$$
\beta_0 \sim \text{t}(3, 1.3, 2.5)
$$
$$
\gamma_0 \sim \text{t}(3, 0, 2.5)
$$

$$
\beta_k, \gamma_k \sim \mathrm{Uniform}
$$


```{r}
#| label: fit-model
#| code-summary: Fit Bayesian model
#| warning: false
#| output: false 

start <- proc.time()
fit <- brm(
    formula = bf(
        shannon ~ Age,
        sigma ~ Age
    ),
    data = df,
    family = student(),
    iter = 4000,
    chains = 4,
    cores = 4
)
end <- proc.time()
runTime_brm <- end - start
```

```{r}
#| label: fit-summary
#| echo: false
#| output: true
    
summary(fit)
```

Interpreting the coefficients and 95% CI we can already make the observation
that the groups `Adult` and `Middle age` differ. The `Middle age` group appears
to have a lower Shannon diversity. 

Further plotting is required to make conclusions on other pair wise comparisons.

```{r}
#| label: plotting-post
#| code-summary: Posterior plotting
#| code-fold: true
#| fig-height: 6
#| fig-width: 12  
  
draws <- as_draws_df(fit)
population <- c(draws$b_Intercept, draws$b_Intercept + draws$b_AgeMiddle_age,  draws$b_Intercept + draws$b_AgeElderly)
pop_mean <- mean(population)

plot_data <- data.frame(
    pop_mean = pop_mean,
    adult = draws$b_Intercept,
    elderly = draws$b_Intercept + draws$b_AgeElderly,
    middle_age = draws$b_Intercept + draws$b_AgeMiddle_age
)

p1 <- ggplot(data = plot_data) +
    geom_density(aes(x = adult), fill = "blue", alpha = 0.5, color = "blue") +
    geom_density(aes(x = middle_age), fill = "orange", alpha = 0.6, color = "orange") +
    geom_density(aes(x = elderly), fill = "purple", alpha = 0.7, color = "purple") +
    geom_vline(xintercept = plot_data$pop_mean, linetype = "dashed", color = "red", linewidth = 1) +
    labs(
        title = "Posterior Distributions of Group means",
        x = "Shannon index",
        y = "Density"
    ) +
    annotate(
        "text", x = 2, y = 2.5,
        label = "Blue: Adult\nOrange: Middle age\nPurple: Elderly"
    ) +
    theme_minimal()

p2 <- ggplot(data = plot_data) +
    geom_boxplot(aes(y = adult, x = 1), fill = "blue", alpha = 0.7, color = "black") +
    geom_boxplot(aes(y = middle_age, x = 2), fill = "orange", alpha = 0.7, color = "black") +
    geom_boxplot(aes(y = elderly, x = 3), fill = "purple", alpha = 0.7, color = "black") +
    geom_hline(yintercept = plot_data$pop_mean, linetype = "dashed", color = "red", linewidth = 1) +
    scale_x_continuous(
        breaks = c(1, 2, 3),
        labels = c("Adult", "Middle Age", "Elderly")
    ) +
    labs(
        title = "Boxplots of Group Means",
        x = "Group",
        y = "Shannon Index"
    ) +
    theme_minimal()

p1 + p2
```

From the plots we can infer groups are not similar. Particularly the 
Middle aged (Orange) group appears to have a lower Shannon index. The boxplots 
paint a clear picture of the higher overlap between the Adult and Edlerly group,
while the Middle aged group differs. In both plots the red dashed line indicates 
the total population posterior mean.

Using the posterior distributions, we can make statements about the differences
between the groups. In this context the probability of observing a higher Shannon index
is appropriate, and akin to a frequentist p-value.

```{r}
#| label: quantify-probabilities
#| code-fold: true
#| code-summary: Quantify probabilities of higher Shannon index

probabilities <- data.frame(
    Comparison = c(
        "Adult vs Elderly",
        "Adult vs Middle age",
        "Elderly vs Middle age"
    ),
    Prob_greater = c(
        prob_adult_elderly <- mean(plot_data$adult > plot_data$elderly),
        prob_adult_middleage <- mean(plot_data$adult > plot_data$middle_age),
        prob_elderly_middleage <- mean(plot_data$elderly > plot_data$middle_age)
    ),
    High_P = c(
        ifelse(prob_adult_elderly > 0.95, "*", ""),
        ifelse(prob_adult_middleage > 0.95, "*", ""),
        ifelse(prob_elderly_middleage > 0.95, "*", "")
    )
)

knitr::kable(probabilities, caption = "Probabilities of Higher Shannon Index", format = "pipe")
```

Notice, that these probabilities are not p-values, and their interpretation is 
more intuitive. The probabilities can also be computed over the highest density interval's (HDI) 
or 95% CI's. Here we have used the full posterior distributions.

# 3. Classical approachs to multi-group testing

## 3.1. ANOVA

ANOVA would be the closest classical alternative. Assumptions in ANOVA are
normality and equal variance. 

```{r}
#| label: annova
start <- proc.time() 
res_annova <- aov(shannon ~ Age, data = df)
end <- proc.time()
runTime_annova <- end - start

summary(res_annova)

```

Our result inidcates that Age is a significant predictor on explaining differences
in the Shannon index. After observing a significant result, it is typical to further
inspect the data with a pairwise t-test. Another option is
Tukey's Honest Significant Difference (HSD). Both of which require adjusting p-values
due to being post-hoc tests.

```{r}
#| label: pairwise-t-test

# Pairwise t-test
start <- proc.time()
pairwise.t.test(df$shannon, df$Age, p.adjust = "fdr")
end <- proc.time()
runTime_pwt <- end - start

# HSD
start <- proc.time()
TukeyHSD(aov(shannon ~ Age, data = df))
end <- proc.time()
runTime_hsd <- end - start
``` 

Both post-hoc tests point to the significant difference between the groups
`Adult` and `Middle age`. In the pairwise t-test the difference between groups
`Middle age` and `Elderly` approaches the significance boundry (p < 0.05).

## 3.2. Kruskal-Wallis

Another option to ANOVA is the Kruskal-Wallis test. Kruskal-Wallis relaxes the
assumption of normality. However, It also needs to be paired with 
a post-hoc test to infer paired differences after global significance has been tested.
Kruskal-Wallis is typically paired with Dunn's post-hoc test.

```{r}
#| label: kruskal-test
start <- proc.time()
kruskal.test(shannon ~ Age, df)
end <- proc.time()
runTime_kw <- end - start
```

We get a p-value < 0.05, so there are 'significant' differences within the groups.

```{r}
#| label: DUNN's test
start <- proc.time()
dunn.test(df$shannon, df$Age, method = "bh", kw = FALSE)
end <- proc.time()
runTime_dunn <- end - start
```

Significant p-values, after adjustment, are reported for the comparison between
groups `Adult` and `Middle age`.

# 4. Conclusions

```{r}
#| label: table-comparison
#| code-fold: true
#| code-summary: Comparison of methods

runTimes <- data.frame(
    method = c(
        "Bayesian estimation",
        "ANNOVA + t.test",
        "ANNOVA + HSD",
        "Kruskal-Wallis + Dunn's"
        ),
    time_seconds = c(
        runTime_brm["elapsed"],
        runTime_annova["elapsed"] + runTime_pwt["elapsed"],
        runTime_annova["elapsed"] + runTime_hsd["elapsed"],
        runTime_kw["elapsed"] + runTime_dunn["elapsed"]
        )
)

knitr::kable(runTimes, caption = "Run times for different methods", format = "pipe")

``` 

Both the probabilistic and classical approachs to multigroup testing give the same result. 
The `Middle age` group is signaled out. Contrasting the methods, it is clear
that the probabilistic approach gives richer inference, with the added benefit
of intuitive interpretation.

The main drawback of the probabilistic approach is the computational cost.
Fitting a Bayesian model, with brms, requires compiling the model and running
the MCMC sampler.